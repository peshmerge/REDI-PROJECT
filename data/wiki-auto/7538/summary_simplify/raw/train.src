A checksum is a small-sized datum derived from a block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage.
By themselves, checksums are often used to verify data integrity but are not relied upon to verify data authenticity.
This is especially true of cryptographic hash functions, which may be used to detect many data corruption errors and verify overall data integrity; if the computed checksum for the current data input matches the stored value of a previously computed checksum, there is a very high probability the data has not been accidentally altered or corrupted.
For instance, a function returning the start of a string can provide a hash appropriate for some applications but will never be a suitable checksum.
Some error-correcting codes are based on special checksums which not only detect common errors but also allow the original data to be recovered in certain cases.
The simplest checksum algorithm is the so-called longitudinal parity check, which breaks the data into "words" with a fixed number "n" of bits, and then computes the exclusive or (XOR) of all those words.
To check the integrity of a message, the receiver computes the exclusive or of all its words, including the checksum; if the result is not a word consisting of "n" zeros, the receiver knows a transmission error occurred.
With this checksum, any transmission error which flips a single bit of the message, or an odd number of bits, will be detected as an incorrect checksum.
However, an error which affects two bits will not be detected if those bits lie at the same position in two distinct words.
A variant of the previous algorithm is to add all the "words" as unsigned binary numbers, discarding any overflow bits, and append the two's complement of the total as the checksum.
To validate a message, the receiver adds all the words in the same manner, including the checksum; if the result is not a word full of zeros, an error must have occurred.
The simple checksums described above fail to detect some common errors which affect many bits at once, such as changing the order of data words, or inserting or deleting words with all bits set to zero.
The checksum algorithms most used in practice, such as Fletcher's checksum, Adler-32, and cyclic redundancy checks (CRCs), address these weaknesses by considering not only the value of each word but also its position in the sequence.
A message that is "m" bits long can be viewed as a corner of the "m"-dimensional hypercube.
The effect of a checksum algorithm that yields an n-bit checksum is to map each "m"-bit message to a corner of a larger hypercube, with dimension .
A single-bit transmission error then corresponds to a displacement from a valid corner (the correct message and checksum) to one of the "m" adjacent corners.
The goal of a good checksum algorithm is to spread the valid corners as far from each other as possible, so as to increase the likelihood "typical" transmission errors will end up in an invalid corner.