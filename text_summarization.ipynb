{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Text summarization- using unsupervised learning\n",
    "\n",
    "###  Given any Input document → sentences similarity → weight sentences → select sentences with higher rank.\n",
    "#### Input article → split into sentences → remove stop words → build a similarity matrix → generate rank based on matrix → pick top N sentences for summary.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    file = open(file_name, \"r\")\n",
    "    return nltk.tokenize.sent_tokenize(file.read())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  similarity matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "\n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "\n",
    "    all_words = list(set(sent1 + sent2))\n",
    "\n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "\n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    "\n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    "\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue\n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "    return similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating a summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# original sentences 22\n",
      "# summarized sentences 12\n",
      "Summarized Text: \n",
      " The Galactic RainCloudS project, an initiative led by members of the Faculty of Physics, the Institute of Cosmos Sciences (ICCUB) of the University of Barcelona and the Institute for Space Studies of Catalonia (IEEC), was awarded the first position in the framework of the Cloud Funding for Research call of the European project Open Clouds For Research Environments (OCRE).. Enrique González Lezana, head of cloud sales specialist at Telefónica Tech, says that “Telefónica has accompanied the University of Barcelona in the definition and unfolding of the Google Cloud architecture, where the required hypercomputing solution to work on the Galactic RainCloudS project will be hosted”.. “Cloud computing is like renting powerful customized computers, for a certain period of time, which will enable us to make the necessary calculations to study the interaction between galaxies”, notes Mercè Romero, researcher at ICCUB.. The research teams’ needs are becoming more specific, and we are making an effort for this project to open the doors of commercial cloud computing in future projects for all research disciplines”, concludes Xavier Luri.. “In Pervasive Technologies, we are glad to offer our knowledge on artificial intelligence and cloud computing to a pioneer project in the field of research.. “Galactic RainCLoudS is a necessary step in the transition of the world of research toward the efficient use of cloud computing resources.. We will work to get the highest performance of the cloud infrastructures and artificial intelligence for this project”, notes Rodolfo Lomascolo, CEO of Pervasive Technologies.. Teresa Antoja, researcher at ICCUB, notes that “the existence of granularities in the galactic halos is a prediction of the current cosmological model of the formation of our Universe: the active search for substructures of this type in the Gaia data can provide vital information on the history of the Milky Way and on the nature of dark matter”.. He adds: “The available big data platforms in the commercial cloud and artificial intelligence services are fundamental tools to find, for instance, whether the interaction of Sagittarius with the Milky Way caused the reignition of the star formation in our galaxy between 5 and 7billion years ago, as stated in some studies”.. Telefónica will work with the UB during the entire process to guarantee the successful implementation of the project with teams specialized on Google Cloud services and technologies”.. Professor Xavier Luri, director of ICCUB and principal researcher of the project, highlights that “The Galactic RainCloudS project is a pioneer one in Europe in the use of commercial cloud infrastructures for research on astronomy, and results from the will to show the benefits of cloud resource uses for the scientific community”.. “The unfolded infrastructure —he adds— will enable the processing and analysis of big data in a flexible, scalable way, adjusted to the required needs of the researchers of the University of Barcelona.\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_file(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
    "\n",
    "    # print(\"Indexes of top ranked_sentence order are \", ranked_sentence)\n",
    "    print(\"# original sentences\" , len(sentences))\n",
    "    print(\"# summarized sentences\" , (int)(len(sentences)/2)+1)\n",
    "    for i in range((int)(len(sentences)/2)+1):\n",
    "        summarize_text.append(\"\".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarized Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "# let's begin\n",
    "generate_summary( \"cloud_computing_eurekalert.txt\", 9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}